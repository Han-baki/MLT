{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page0\n",
    "#input\n",
    "#train_ImagesPart1_dir : ImagesPart1의 image파일이 있는 directory\n",
    "#train_ImagesPart2_dir : ImagesPart2의 image파일이 있는 directory\n",
    "#train_gt_dir : train_gt_t13의 text파일이 있는 directory\n",
    "#test_img_dir : 2017 validation data의 image파일이 있는 directory\n",
    "#test_gt_dir : 2017 validation data의 text파일이 있는 directory\n",
    "\n",
    "train_ImagesPart1_dir = 'ImagesPart1'\n",
    "train_ImagesPart2_dir = 'ImagesPart2'\n",
    "train_gt_dir = 'train_gt_t13'\n",
    "test_img_dir = '2017_validation/img'\n",
    "test_gt_dir = '2017_validation/txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making the train, test set directory..\n",
      "9005\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#page1\n",
    "# making data directories\n",
    "from make_data import make_batch_idx, save_imgs_to_dir, save_txt_to_dir\n",
    "\n",
    "# sample data를 train 2000개, validation 200개 data로 나누어 만듦\n",
    "validation_set,_,_,_,_ = make_batch_idx(train_gt_dir,200)\n",
    "validation_list = list(validation_set)\n",
    "validation_list.sort()\n",
    "save_imgs_to_dir(train_ImagesPart1_dir,train_ImagesPart2_dir,validation_list,'sample_validation/img')\n",
    "save_txt_to_dir(train_gt_dir,validation_list,'sample_validation/txt')\n",
    "\n",
    "train_set,_,_,_,_ = make_batch_idx(train_gt_dir,2000,except_list = validation_list)\n",
    "train_list = list(train_set)\n",
    "train_list.sort()\n",
    "save_imgs_to_dir(train_ImagesPart1_dir,train_ImagesPart2_dir,train_list,'sample_train/img')\n",
    "save_txt_to_dir(train_gt_dir,train_list,'sample_train/txt')\n",
    "\n",
    "# 10000개의 이미지 중 sample data와 error_gif_idx를 제외하고 test data 941개를 만들고,\n",
    "                #나머지에서 error_gif_idx=54개를 제외한 9005개를 training data로 만드는 코드\n",
    "print('making the train, test set directory..')\n",
    "error_gif_idx=[101, 164, 1437, 1476, 1673, 2645, 2710, 4191, 4195, 4501, 4555, 5040, 5167, 5305, 5453, 5492, 5535, 5644, 5660, 5736, 5770, 5770, 5770, 5778, 5859, 5865, 5878, 5878, 5997, 6109, 6181, 6206, 6408, 6670, 6788, 6803, 6952, 7030, 7061, 7062, 7073, 7173, 7191, 7216, 7216, 7288, 7429, 7504, 7509, 7513, 7566, 7628, 7643, 7947, 8062, 8295, 8295, 8393, 8845]\n",
    "except_list = validation_list + train_list + error_gif_idx\n",
    "test_set,_,_,_,_ = make_batch_idx(train_gt_dir,941,except_list = except_list)\n",
    "test_list = list(test_set)\n",
    "test_list.sort()\n",
    "save_imgs_to_dir(train_ImagesPart1_dir,train_ImagesPart2_dir,test_list,'test/img')\n",
    "save_txt_to_dir(train_gt_dir,test_list,'test/txt')\n",
    "\n",
    "other_set = set(list(range(10000)))-test_set\n",
    "other_set = other_set - set(error_gif_idx)\n",
    "other_idx = list(other_set)\n",
    "other_idx.sort()\n",
    "save_imgs_to_dir(train_ImagesPart1_dir,train_ImagesPart2_dir,other_idx,'train/img')\n",
    "save_txt_to_dir(train_gt_dir,other_idx,'train/txt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to ICDAR2019_train.pkl...\n",
      "done\n",
      "save to ICDAR2019_test.pkl...\n",
      "done\n",
      "save to ICDAR2017_validation.pkl...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#page2\n",
    "#train 9005개, test 941개, 2017 validation data 1800개에 대한 pkl파일 만들기\n",
    "import pickle\n",
    "from data_generate import GTUtility\n",
    "\n",
    "#train data save as pkl\n",
    "gt_util = GTUtility(image_path = 'train/img', gt_path = 'train/txt')\n",
    "file_name = 'ICDAR2019_train.pkl'\n",
    "print('save to %s...' % file_name)\n",
    "pickle.dump(gt_util, open(file_name,'wb'))\n",
    "print('done')\n",
    "\n",
    "#test data save as pkl\n",
    "gt_util = GTUtility(image_path = 'test/img', gt_path = 'test/txt')\n",
    "file_name = 'ICDAR2019_test.pkl'\n",
    "print('save to %s...' % file_name)\n",
    "pickle.dump(gt_util, open(file_name,'wb'))\n",
    "print('done')\n",
    "\n",
    "#2017 validation data save as pkl\n",
    "gt_util = GTUtility(image_path = test_img_dir, gt_path = test_gt_dir, val = True)\n",
    "file_name = 'ICDAR2017_validation.pkl'\n",
    "print('save to %s...' % file_name)\n",
    "pickle.dump(gt_util, open(file_name,'wb'))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 epoch training..\n",
      "Epoch 1/40\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0005.\n",
      "   2/1801 [..............................] - ETA: 10:55:15 - loss: 946.1182 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-149a84d66488>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 ], \n\u001b[0;32m     60\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         )\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#page3 \n",
    "# main training\n",
    "# ICDAR2019_train.pkl에 저장된 이미지 9005개를 학습\n",
    "# 1~20 epoch learning rate = 5*e-4\n",
    "# 21~40 epoch learning rate = 2*e-4\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "from utils.model import load_weights\n",
    "from data_generate import GTUtility, InputGenerator\n",
    "from tbpp_model import TBPP512\n",
    "from default_box import PriorUtil\n",
    "from focal_loss import TBPPFocalLoss\n",
    "\n",
    "with open('ICDAR2019_train.pkl', 'rb') as f:\n",
    "    gt_util_train = pickle.load(f)\n",
    "    \n",
    "K.clear_session()\n",
    "model = TBPP512(softmax=False)\n",
    "weights_path =None\n",
    "if weights_path is not None:\n",
    "    load_weights(model, weights_path)\n",
    "prior_util = PriorUtil(model)\n",
    "batch_size = 5\n",
    "gen_train = InputGenerator(gt_util_train, prior_util, batch_size, model.image_size)\n",
    "experiment = 'tbpp512fl_synthtext'\n",
    "epochs = 40\n",
    "initial_epoch = 0\n",
    "\n",
    "print('40 epoch training..')\n",
    "checkdir = './checkpoints/' + time.strftime('%Y%m%d%H%M') + '_' + experiment\n",
    "if not os.path.exists(checkdir):\n",
    "    os.makedirs(checkdir)\n",
    "\n",
    "optim = keras.optimizers.Adam(lr=5*1e-4, beta_1=0.9, beta_2=0.999, epsilon=0.001)\n",
    "loss = TBPPFocalLoss(lambda_conf=1000.0, lambda_offsets=0.1)\n",
    "model.compile(optimizer=optim, loss=loss.compute)\n",
    "    \n",
    "def schedule(x):\n",
    "    if x < 20:\n",
    "        lr = 0.0005\n",
    "    else:\n",
    "        lr = 0.0002\n",
    "    return lr\n",
    "    \n",
    "history = model.fit_generator(\n",
    "        gen_train.generate(seed = None),\n",
    "        steps_per_epoch=int(gen_train.num_batches), \n",
    "        epochs=epochs, \n",
    "        verbose=1, \n",
    "        callbacks=[\n",
    "                keras.callbacks.ModelCheckpoint(checkdir+'/weights.{epoch:03d}.h5', verbose=1, save_weights_only=True), \n",
    "                keras.callbacks.LearningRateScheduler(schedule, verbose = 1),\n",
    "                ], \n",
    "        class_weight=None,\n",
    "        initial_epoch=initial_epoch, \n",
    "        )\n",
    "\n",
    "\n",
    "print('done')\n",
    "print('train done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid searching of confidence threshold by test data\n",
      "5/5 [==============================] - 6s 1s/step\n",
      "threshold 0.05 f-measure 0.00\n",
      "threshold 0.10 f-measure 0.00\n",
      "threshold 0.15 f-measure 0.00\n",
      "threshold 0.20 f-measure 0.00\n",
      "threshold 0.25 f-measure 0.00\n",
      "threshold 0.30 f-measure 0.00\n",
      "threshold 0.35 f-measure 0.00\n",
      "threshold 0.40 f-measure 0.00\n",
      "threshold 0.45 f-measure 0.00\n",
      "threshold 0.50 f-measure 0.00\n",
      "threshold 0.55 f-measure 0.00\n",
      "threshold 0.60 f-measure 0.00\n",
      "threshold 0.65 f-measure 0.00\n",
      "threshold 0.70 f-measure 0.00\n",
      "threshold 0.75 f-measure 0.00\n",
      "0.05 0.00437636761487965\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#page4\n",
    "#Grid search\n",
    "#ICDAR2019_test.pkl에 저장된 test data에서 random하게 이미지 500개를 불러와\n",
    "    #가장 적절한 confidence threshold를 grid search 방법으로 탐색\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "from utils.model import load_weights\n",
    "from tbpp_evaluate import prh\n",
    "from default_box import PriorUtil\n",
    "from tbpp_model import TBPP512\n",
    "\n",
    "print('Grid searching of confidence threshold by test data')\n",
    "with open('ICDAR2019_test.pkl', 'rb') as f:\n",
    "    gt_util_test = pickle.load(f)\n",
    "\n",
    "#model\n",
    "weights_path = None\n",
    "if weights_path:\n",
    "    K.clear_session()\n",
    "    modelJ = TBPP512(softmax=False)\n",
    "    load_weights(modelJ, weights_path)\n",
    "else:\n",
    "    modelJ = model\n",
    "    \n",
    "prior_util = PriorUtil(modelJ)\n",
    "\n",
    "#Prediction\n",
    "sample_batch_num = 500\n",
    "_, inputs, images, data = gt_util_test.sample_random_batch(sample_batch_num, seed = None) \n",
    "\n",
    "preds = modelJ.predict(inputs, batch_size=1, verbose=1)\n",
    "\n",
    "#Grid Search\n",
    "steps = np.arange(0.05, 0.8, 0.05)\n",
    "fmes_grid = np.zeros((len(steps)))\n",
    "\n",
    "for i, t in enumerate(steps):\n",
    "    results = [prior_util.decode(p, t) for p in preds]\n",
    "    gt_input = [np.concatenate([g[:,0:8], np.argmax(g[:,8:],axis=1).reshape(-1,1)], axis = 1) for g in data]\n",
    "    pred_input = [np.concatenate([d[:,4:12], d[:,18].reshape(-1,1)], axis=1) for d in results] \n",
    "    precision, recall, fmes = prh(gt_input, pred_input)\n",
    "\n",
    "    fmes_grid[i] = fmes\n",
    "    print('threshold %.2f f-measure %.2f' % (t, fmes))\n",
    "    \n",
    "max_idx = np.argmax(fmes_grid)\n",
    "print(steps[max_idx], fmes_grid[max_idx])\n",
    "plt.figure(figsize=[12,6])\n",
    "plt.plot(steps, fmes_grid)\n",
    "plt.plot(steps[max_idx], fmes_grid[max_idx], 'or')\n",
    "plt.xticks(steps)\n",
    "plt.grid()\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('f-measure')\n",
    "plt.show()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score of 2017 validation data\n",
      "   6/1800 [..............................] - ETA: 38:15"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ec6f8dfd3722>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgt_util_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_random_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_batch_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelJ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#수정 한상준10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mconfidence_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprior_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence_threshold\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#page5\n",
    "#ICDAR2017_validation.pkl에 저장된 ICDAR 2017 validation data 1800개를 불러와\n",
    "    #최종 precision, recall, f1 score를 계산\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "from utils.model import load_weights\n",
    "from tbpp_evaluate import prh, prh_txt\n",
    "from default_box import PriorUtil\n",
    "from tbpp_model import TBPP512\n",
    "\n",
    "print('f1 score of 2017 validation data')\n",
    "with open('ICDAR2017_validation.pkl', 'rb') as f:\n",
    "    gt_util_test = pickle.load(f)\n",
    "\n",
    "#model\n",
    "weights_path = None\n",
    "if weights_path:\n",
    "    K.clear_session()\n",
    "    modelJ = TBPP512(softmax=False)\n",
    "    load_weights(modelJ, weights_path)\n",
    "else:\n",
    "    modelJ = model\n",
    "    \n",
    "prior_util = PriorUtil(modelJ)\n",
    "\n",
    "#Prediction\n",
    "sample_batch_num = 1800 #validation 갯수\n",
    "_, inputs, images, data = gt_util_test.sample_random_batch(sample_batch_num, seed = None) \n",
    "\n",
    "preds = modelJ.predict(inputs, batch_size=1, verbose=1) #수정 한상준10\n",
    "confidence_threshold = 0.4\n",
    "results = [prior_util.decode(p, confidence_threshold) for p in preds]\n",
    "gt_input = [np.concatenate([g[:,0:8], np.argmax(g[:,8:],axis=1).reshape(-1,1)], axis = 1) for g in data]\n",
    "pred_input = [np.concatenate([d[:,4:12], d[:,18].reshape(-1,1)], axis=1) for d in results] \n",
    "prec_total, recall_total, fmes_total = prh(gt_input, pred_input)\n",
    "prec_txt, recall_txt, fmes_txt = prh_txt(gt_input,pred_input)\n",
    "\n",
    "print('(text detection + classification) precision, recall, f1 score : ',prec_total, recall_total, fmes_total)\n",
    "print('(text detection) precision, recall, f1 score : ',prec_txt, recall_txt, fmes_txt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
